{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install pyscreenshot\n",
    "# pip install opencv-python\n",
    "# pip install imutils\n",
    "# pip install cmake\n",
    "# pip install dlib\n",
    "# pip install git+https://github.com/ageitgey/face_recognition_models\n",
    "\n",
    "# If error with version, using pip install Pillow==6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from skimage.measure import compare_ssim\n",
    "import pyscreenshot as ImageGrab\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_crop(image):\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    if face_locations:     #  prevent manipulation of null variable\n",
    "        top, right, bottom, left = face_locations[0]\n",
    "\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        image = image[top:bottom, left:right]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def screen_diff(imageA, imageB):\n",
    "    grayA = cv2.cvtColor(np.float32(imageA), cv2.COLOR_BGR2GRAY)\n",
    "    grayB = cv2.cvtColor(np.float32(imageB), cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    (score, diff) = compare_ssim(grayA, grayB, full=True)\n",
    "    print(\"SSIM Screen: {}\".format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def face_diff(imageA, imageB):\n",
    "#     max_w, max_h = None, None\n",
    "#     if imageA.shape[:2] != imageB.shape[:2]:\n",
    "#         max_w = max(imageA.shape[0], imageB.shape[0])\n",
    "#         max_h = max(imageA.shape[1], imageB.shape[1])\n",
    "    \n",
    "#     # convert the images to grayscale\n",
    "#     if max_w or max_h:\n",
    "#         grayA = cv2.cvtColor(\n",
    "#             imutils.resize(imageA, width=max_w, height=max_h), cv2.COLOR_BGR2GRAY)\n",
    "#         grayB = cv2.cvtColor(\n",
    "#             imutils.resize(imageB, width=max_w, height=max_h), cv2.COLOR_BGR2GRAY)\n",
    "#         if grayA.shape != grayB.shape:\n",
    "#             gray_max_w = max(grayA.shape[0], grayB.shape[0])\n",
    "#             gray_max_h = max(grayA.shape[1], grayB.shape[1])\n",
    "#             right_a, bottom_a = gray_max_h-grayA.shape[1],  gray_max_w-grayA.shape[0]\n",
    "#             right_b, bottom_b = gray_max_h-grayB.shape[1],  gray_max_w-grayB.shape[0]\n",
    "#             if (bottom_a, right_a) != (0, 0):\n",
    "#                 grayA = cv2.copyMakeBorder(\n",
    "#                     grayA, 0, bottom_a, 0, right_a,\n",
    "#                     cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "#             if (bottom_b, right_b) != (0, 0):\n",
    "#                 o_grayB = grayB.copy()\n",
    "#                 grayB = cv2.copyMakeBorder(\n",
    "#                     grayB, 0, bottom_b, 0, right_b,\n",
    "#                     cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "#     else:\n",
    "\n",
    "    grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "    grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    (score, diff) = compare_ssim(grayA, grayB, full=True)\n",
    "    print(\"SSIM Face: {}\".format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "hr_report = pd.DataFrame(columns = ['Time', 'Note', 'Image_Before', 'Image_After'])\n",
    "workingtime = 0\n",
    "freetime = 0\n",
    "timestep = 2\n",
    "# X1,Y1,X2,Y2\n",
    "X1 = 600\n",
    "Y1 = 300\n",
    "X2 = 1400\n",
    "Y2 = 700\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "ret, frame_before2 = video_capture.read()\n",
    "screen_before2 = ImageGrab.grab(bbox=(X1,Y1,X2,Y2))\n",
    "# print(datetime.fromtimestamp(time.time()).strftime(\"%A, %B %d, %Y %I:%M:%S\"))\n",
    "# plt.subplot(122), plt.imshow(frame_before2)\n",
    "# plt.subplot(121), plt.imshow(screen_before2)\n",
    "# plt.show()\n",
    "\n",
    "time.sleep(timestep)\n",
    "\n",
    "ret, frame_before1 = video_capture.read()\n",
    "screen_before1 = ImageGrab.grab(bbox=(X1,Y1,X2,Y2))\n",
    "# print(datetime.fromtimestamp(time.time()).strftime(\"%A, %B %d, %Y %I:%M:%S\"))\n",
    "# plt.subplot(122), plt.imshow(frame_before1)\n",
    "# plt.subplot(121), plt.imshow(screen_before1)\n",
    "# plt.show()\n",
    "\n",
    "time.sleep(timestep)\n",
    "\n",
    "t_start = time.time()\n",
    "while True:\n",
    "    # Stop\n",
    "    if (time.time() - 10) > t_start:\n",
    "        video_capture.release()\n",
    "        break\n",
    "    t = time.time()    \n",
    "    # Grabbing frames\n",
    "    ret, frame = video_capture.read()\n",
    "    screen = ImageGrab.grab(bbox=(X1,Y1,X2,Y2))\n",
    "    \n",
    "    time_check = datetime.fromtimestamp(time.time()).strftime(\"%A, %B %d, %Y %I:%M:%S\")\n",
    "#     print(time_check)\n",
    "#     plt.subplot(122), plt.imshow(frame)\n",
    "#     plt.subplot(121), plt.imshow(screen)\n",
    "#     plt.show()\n",
    "        \n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    \n",
    "    if len(face_locations) == 0:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        eyes = eye_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        if len(eyes) == 0:\n",
    "            df_temp = pd.DataFrame(columns = ['Time', 'Note', 'Image_Before', 'Image_After'])\n",
    "            df_temp['Time'] = [time_check]\n",
    "            df_temp['Note'] = ['Can not detect face']      \n",
    "            df_temp['Image_After'] = [frame]\n",
    "            hr_report = pd.concat([hr_report, df_temp])\n",
    "\n",
    "            freetime += timestep + time.time() - t\n",
    "            \n",
    "        else:\n",
    "            workingtime += timestep + time.time() - t\n",
    "            screen_before2 = screen_before1\n",
    "            screen_before1 = screen\n",
    "            frame_before2 = frame_before1\n",
    "            frame_before1 = frame\n",
    "    else:        \n",
    "            \n",
    "        if (screen_diff(screen_before1, screen) > 0.8) and (screen_diff(screen_before2, screen) > 0.8):\n",
    "            freetime += timestep + time.time() - t\n",
    "            df_temp = pd.DataFrame(columns = ['Time', 'Note', 'Image_Before', 'Image_After'])\n",
    "            df_temp['Time'] = [time_check]\n",
    "            df_temp['Note'] = ['Screen no change']\n",
    "            df_temp['Image_Before'] = [screen_before2]\n",
    "            df_temp['Image_After'] = [screen]\n",
    "            hr_report = pd.concat([hr_report, df_temp])\n",
    "            \n",
    "        if (face_diff(frame_before1, frame) > 0.8) and (face_diff(frame_before2, frame) > 0.8):\n",
    "            freetime += timestep + time.time() - t\n",
    "            df_temp = pd.DataFrame(columns = ['Time', 'Note', 'Image_Before', 'Image_After'])\n",
    "            df_temp['Time'] = [time_check]\n",
    "            df_temp['Note'] = ['Webcam no change']\n",
    "            df_temp['Image_Before'] = [frame_before2]\n",
    "            df_temp['Image_After'] = [frame]\n",
    "            hr_report = pd.concat([hr_report, df_temp])\n",
    "    \n",
    "        else:\n",
    "            workingtime += timestep + time.time() - t\n",
    "            screen_before2 = screen_before1\n",
    "            screen_before1 = screen\n",
    "            frame_before2 = frame_before1\n",
    "            frame_before1 = frame\n",
    "            \n",
    "    print('working time: %ss - free time: %ss' % (workingtime, freetime))\n",
    "    time.sleep(timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_capture.release()\n",
    "hr_report = hr_report.reset_index(drop=True)\n",
    "hr_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    img = hr_report['Image_After'][0]\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "except:\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
